{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### ECHO Metrics Functions and Code"
      ],
      "metadata": {
        "id": "1OyIdRDNoL3A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Total Harmonic Distortion: WORKING\n",
        "Note there are some files where the fundamental frequency is too high for any type of THD calculation. Should ask Dr.Shah about what this means and how we can go about interpreting this for our benchmarking"
      ],
      "metadata": {
        "id": "a8YJk-FCogLp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWiEnioaoKvq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import scipy.signal\n",
        "\n",
        "def calculate_thd_dynamic(audio_file):\n",
        "    # Load the audio signal\n",
        "    signal, sr = librosa.load(audio_file, sr=None)\n",
        "\n",
        "    # Perform FFT on the signal\n",
        "    fft_spectrum = np.fft.fft(signal)\n",
        "    fft_magnitude = np.abs(fft_spectrum[:len(fft_spectrum) // 2])  # Only keep positive frequencies\n",
        "    freqs = np.fft.fftfreq(len(signal), d=1/sr)[:len(fft_spectrum) // 2]\n",
        "\n",
        "    # Find peaks in the FFT spectrum\n",
        "    peaks, properties = scipy.signal.find_peaks(fft_magnitude, height=np.max(fft_magnitude) * 0.1)  # Consider peaks above 10% max amplitude\n",
        "\n",
        "    if len(peaks) < 2:\n",
        "        raise ValueError(f\"Not enough peaks found to compute THD in file: {audio_file}\")\n",
        "\n",
        "    # Sort peaks by amplitude (descending)\n",
        "    sorted_indices = np.argsort(properties[\"peak_heights\"])[::-1]\n",
        "    sorted_peaks = peaks[sorted_indices]\n",
        "\n",
        "    # Assume the highest peak is the fundamental frequency\n",
        "    fundamental_freq = freqs[sorted_peaks[0]]\n",
        "    fundamental_amp = fft_magnitude[sorted_peaks[0]]\n",
        "\n",
        "    # Compute THD by summing the power of the harmonics\n",
        "    harmonic_power = 0\n",
        "    for peak in sorted_peaks[1:]:  # Ignore fundamental, check harmonics\n",
        "        harmonic_freq = freqs[peak]\n",
        "        if np.isclose(harmonic_freq % fundamental_freq, 0, atol=1):  # Ensure it's a harmonic\n",
        "            harmonic_power += fft_magnitude[peak] ** 2\n",
        "\n",
        "    if harmonic_power == 0:\n",
        "        raise ValueError(f\"No harmonics found for THD calculation in file: {audio_file}\")\n",
        "\n",
        "    thd = (np.sqrt(harmonic_power) / fundamental_amp)\n",
        "    return thd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: run the thd funciton above on all .wav files\n",
        "\n",
        "import numpy as np\n",
        "import librosa\n",
        "import glob\n",
        "\n",
        "# ### ECHO Metrics Functions and Code\n",
        "# ##Total Harmonic Distortion:\n",
        "# Note there are some files where the fundamental frequency is too high for any type of THD calculation. Should ask Dr.Shah about what this means and how we can go about interpreting this for our benchmarking\n",
        "\n",
        "\n",
        "\n",
        "# Find all .wav files in the current directory\n",
        "wav_files = glob.glob(\"*.wav\")\n",
        "\n",
        "# Process each .wav file\n",
        "for file in wav_files:\n",
        "    thd = calculate_thd_dynamic(file)\n",
        "    print(f\"THD for {file}: {thd}\")\n"
      ],
      "metadata": {
        "id": "0uSXwIVil2B1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Noise Floor: (WORKING)\n",
        "Note this is all calculated in decibels. Negative values indicate fractions of average signal power. For instance, -20 dB indicates that the signal's power is one-tenth of the reference power, while -40 dB means it's one-hundredth."
      ],
      "metadata": {
        "id": "-SM-6Ku-o73B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppZmL3A_o73E"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "def noiseFloor(audio_file, segment_duration=0.5):\n",
        "    # Load the audio signal\n",
        "    signal, sr = librosa.load(audio_file, sr=None)\n",
        "\n",
        "    # Calculate segment length in samples\n",
        "    segment_length = int(segment_duration * sr)\n",
        "\n",
        "    # Split the signal into segments\n",
        "    segments = [signal[i:i + segment_length] for i in range(0, len(signal), segment_length)]\n",
        "\n",
        "    # Calculate RMS for each segment\n",
        "    rms_values = [np.sqrt(np.mean(segment**2)) for segment in segments]\n",
        "\n",
        "    # Average RMS value as the noise floor\n",
        "    noise_floor = np.mean(rms_values)\n",
        "\n",
        "    # Convert to decibels\n",
        "    noise_floor_db = 20 * np.log10(noise_floor)\n",
        "\n",
        "    return noise_floor_db"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: run noiseFloor(file) for every .wav file in this folder\n",
        "\n",
        "import os\n",
        "\n",
        "# Assuming the .wav files are in the current directory\n",
        "for filename in os.listdir('.'):\n",
        "  if filename.endswith('.wav'):\n",
        "    noise_floor_value = noiseFloor(filename)\n",
        "    print(f\"Noise floor for {filename}: {noise_floor_value} dB\")\n"
      ],
      "metadata": {
        "id": "BW3RaEREaiWz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0c90f06-b29d-423e-9acc-e44c5f89707e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Noise floor for D-N00-003.wav: -47.45856285095215 dB\n",
            "Noise floor for P-N00-009.wav: -36.37200117111206 dB\n",
            "Noise floor for N-M04-004.wav: -36.63763761520386 dB\n",
            "Noise floor for I-F01-001.wav: -37.72143363952637 dB\n",
            "Noise floor for H-N00-004.wav: -34.67665433883667 dB\n",
            "Noise floor for O-N00-009.wav: -35.19062280654907 dB\n",
            "Noise floor for C-N00-002.wav: -42.962965965270996 dB\n",
            "Noise floor for M-M05-001.wav: -38.46359729766846 dB\n",
            "Noise floor for B-M02-004.wav: -46.11800193786621 dB\n",
            "Noise floor for F-M06-005.wav: -42.31052875518799 dB\n",
            "Noise floor for G-N00-006.wav: -26.650385856628418 dB\n",
            "Noise floor for J-F03-001.wav: -34.73475217819214 dB\n",
            "Noise floor for E-M06-004.wav: -28.192243576049805 dB\n",
            "Noise floor for K-N00-001.wav: -35.37731409072876 dB\n",
            "Noise floor for A-M02-002.wav: -35.961761474609375 dB\n",
            "Noise floor for L-N00-001.wav: -39.15335655212402 dB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dynamic Range (WORKING)\n"
      ],
      "metadata": {
        "id": "u9nRJyK9zzk4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLdc8zlIzzk7"
      },
      "outputs": [],
      "source": [
        "### Insert Code Here\n",
        "\n",
        "import numpy as np\n",
        "import scipy.io.wavfile as wav\n",
        "\n",
        "def calculate_dynamic_range(wav_file):\n",
        "    \"\"\"\n",
        "    Calculates the dynamic range of a .wav file.\n",
        "\n",
        "    Args:\n",
        "        wav_file (str): Path to the .wav file.\n",
        "\n",
        "    Returns:\n",
        "        float: Dynamic range in decibels (dB).\n",
        "    \"\"\"\n",
        "    # Read the wav file\n",
        "    sample_rate, data = wav.read(wav_file)\n",
        "\n",
        "    # Convert to mono if stereo\n",
        "    if len(data.shape) > 1:\n",
        "        data = np.mean(data, axis=1)  # Take mean of channels to make mono\n",
        "\n",
        "    # Compute peak amplitude\n",
        "    peak_amplitude = np.max(np.abs(data))\n",
        "\n",
        "    # Compute RMS amplitude\n",
        "    rms_amplitude = np.sqrt(np.mean(data**2))\n",
        "\n",
        "    # Avoid division by zero\n",
        "    if rms_amplitude == 0:\n",
        "        return float('inf')  # Infinite dynamic range if there is no signal\n",
        "\n",
        "    # Compute dynamic range in dB\n",
        "    dynamic_range = 20 * np.log10(peak_amplitude / rms_amplitude)\n",
        "\n",
        "    return dynamic_range\n",
        "\n",
        "# Example usage:\n",
        "# print(calculate_dynamic_range(\"example.wav\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Assuming the .wav files are in the current directory\n",
        "for filename in os.listdir('.'):\n",
        "  if filename.endswith('.wav'):\n",
        "    dyn = calculate_dynamic_range(filename)\n",
        "    print(f\"Dynamic range for {filename}: {dyn} dB\")"
      ],
      "metadata": {
        "id": "YABEfxvNnapt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Crest Factor: (WORKING)"
      ],
      "metadata": {
        "id": "ZsHjkZlk0Gob"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzVLFIaP0Goc"
      },
      "outputs": [],
      "source": [
        "### Ronoy\n",
        "\n",
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "def crestFactor(audio_file, segment_duration=0.5):\n",
        "    # Load the audio signal\n",
        "    signal, sr = librosa.load(audio_file, sr=None)\n",
        "\n",
        "    # Calculate segment length in samples\n",
        "    segment_length = int(segment_duration * sr)\n",
        "\n",
        "    # Split the signal into segments\n",
        "    segments = [signal[i:i + segment_length] for i in range(0, len(signal), segment_length)]\n",
        "\n",
        "    # Calculate peak and RMS for each segment\n",
        "    crest_factors = []\n",
        "    for segment in segments:\n",
        "        peak = np.max(np.abs(segment))\n",
        "        rms = np.sqrt(np.mean(segment**2))\n",
        "        crest_factor = peak / rms if rms > 0 else 0  # Avoid division by zero\n",
        "        crest_factors.append(crest_factor)\n",
        "\n",
        "    # Average crest factor across segments\n",
        "    average_crest_factor = np.mean(crest_factors)\n",
        "\n",
        "    return average_crest_factor\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: run crest factor for every .wav file in this folder\n",
        "\n",
        "import numpy as np\n",
        "import librosa\n",
        "import os\n",
        "\n",
        "# ... (rest of your code, including the noiseFloor and calculate_thd_dynamic functions)\n",
        "\n",
        "# Assuming the .wav files are in the current directory\n",
        "for filename in os.listdir('.'):\n",
        "  if filename.endswith('.wav'):\n",
        "    noise_floor_value = noiseFloor(filename)\n",
        "    print(f\"Noise floor for {filename}: {noise_floor_value} dB\")\n",
        "\n",
        "    crest_factor_value = crestFactor(filename)\n",
        "    print(f\"Crest factor for {filename}: {crest_factor_value}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "G8d_VWl8Z10x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "```\n",
        "\n",
        "##Waveform Complexity Index:"
      ],
      "metadata": {
        "id": "Mo7y9nD_10bn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import scipy.stats\n",
        "\n",
        "def calculate_waveform_complexity(audio_file):\n",
        "    # Load audio file\n",
        "    signal, sr = librosa.load(audio_file, sr=None, mono=True)\n",
        "\n",
        "    # Compute Zero-Crossing Rate (ZCR) - Measures frequency of sign changes\n",
        "    zcr = librosa.feature.zero_crossing_rate(y=signal)\n",
        "    avg_zcr = np.mean(zcr)\n",
        "\n",
        "    # Compute Spectral Entropy manually (Energy Distribution across Frequencies)\n",
        "    spectrum = np.abs(librosa.stft(signal))  # Compute magnitude spectrum\n",
        "    spectrum = spectrum / np.sum(spectrum, axis=0, keepdims=True)  # Normalize\n",
        "    spectral_entropy = scipy.stats.entropy(spectrum, axis=0)  # Compute entropy\n",
        "    avg_entropy = np.mean(spectral_entropy)\n",
        "\n",
        "    # Compute RMS Energy Variation - Measures fluctuations in loudness\n",
        "    rms_energy = librosa.feature.rms(y=signal)\n",
        "    rms_variation = np.std(rms_energy)  # Standard deviation to measure fluctuation\n",
        "\n",
        "    # Compute Waveform Complexity Index (WCI)\n",
        "    wci = (avg_zcr * avg_entropy) / (1 + rms_variation)  # Normalize by dynamic range\n",
        "\n",
        "    print(f\"Waveform Complexity Index for {audio_file}: {wci:.4f}\")\n",
        "    return wci\n",
        "\n"
      ],
      "metadata": {
        "id": "HtFFHeXV1xJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: run waveform complexity (WCI)  factor for every .wav file in this folder\n",
        "\n",
        "import numpy as np\n",
        "import librosa\n",
        "import scipy.signal\n",
        "import glob\n",
        "import os\n",
        "import scipy.io.wavfile as wav\n",
        "\n",
        "\n",
        "\n",
        "# Find all .wav files in the current directory\n",
        "wav_files = glob.glob(\"*.wav\")\n",
        "\n",
        "# Process each .wav file\n",
        "for file in wav_files:\n",
        "    calculate_waveform_complexity(file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGlzKlnj2FVQ",
        "outputId": "4e821abe-590a-4058-fbaf-88d096c93a9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Waveform Complexity Index for D-N00-003.wav: 0.3343\n",
            "Waveform Complexity Index for P-N00-009.wav: 0.0594\n",
            "Waveform Complexity Index for N-M04-004.wav: 0.1023\n",
            "Waveform Complexity Index for I-F01-001.wav: 0.1686\n",
            "Waveform Complexity Index for H-N00-004.wav: 0.4746\n",
            "Waveform Complexity Index for O-N00-009.wav: 0.1211\n",
            "Waveform Complexity Index for C-N00-002.wav: 0.3496\n",
            "Waveform Complexity Index for M-M05-001.wav: 0.1596\n",
            "Waveform Complexity Index for B-M02-004.wav: 0.5198\n",
            "Waveform Complexity Index for F-M06-005.wav: 0.2073\n",
            "Waveform Complexity Index for G-N00-006.wav: 0.5155\n",
            "Waveform Complexity Index for J-F03-001.wav: 0.3211\n",
            "Waveform Complexity Index for E-M06-004.wav: 0.0819\n",
            "Waveform Complexity Index for K-N00-001.wav: 0.1762\n",
            "Waveform Complexity Index for A-M02-002.wav: 0.4618\n",
            "Waveform Complexity Index for L-N00-001.wav: 0.1828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SNR: WORKING"
      ],
      "metadata": {
        "id": "LVh551TG0Tm9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIQc3tzO0Tm_"
      },
      "outputs": [],
      "source": [
        "### Ronoy\n",
        "\n",
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "def snr(audio_file, noise_duration=0.5, signal_duration=2.0):\n",
        "    # Load the audio signal\n",
        "    signal, sr = librosa.load(audio_file, sr=None)\n",
        "\n",
        "    # Calculate noise and signal lengths in samples\n",
        "    noise_length = int(noise_duration * sr)\n",
        "    signal_length = int(signal_duration * sr)\n",
        "\n",
        "    # Get noise and signal segments\n",
        "    noise_segment = signal[:noise_length]\n",
        "    signal_segment = signal[noise_length:noise_length + signal_length]\n",
        "\n",
        "    # Calculate RMS of noise and signal\n",
        "    noise_rms = np.sqrt(np.mean(noise_segment**2))\n",
        "    signal_rms = np.sqrt(np.mean(signal_segment**2))\n",
        "\n",
        "    # Calculate SNR in decibels\n",
        "    snr_db = 20 * np.log10(signal_rms / noise_rms) if noise_rms > 0 else float('inf')  # Avoid division by zero\n",
        "\n",
        "    return snr_db\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: run snr on all .wav files\n",
        "\n",
        "import numpy as np\n",
        "import librosa\n",
        "import os\n",
        "\n",
        "# ... (Your existing code for THD, noiseFloor, crestFactor, and snr functions)\n",
        "\n",
        "# Assuming the .wav files are in the current directory\n",
        "for filename in os.listdir('.'):\n",
        "    if filename.endswith('.wav'):\n",
        "        try:\n",
        "            snr_value = snr(filename)\n",
        "            print(f\"SNR for {filename}: {snr_value} dB\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {filename}: {e}\")\n"
      ],
      "metadata": {
        "id": "oMPOum9Ia4-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastdtw"
      ],
      "metadata": {
        "id": "s_bGt5OX1RSy",
        "outputId": "e4b9a7c8-fc39-4a34-ad67-f93dd9e48862",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fastdtw\n",
            "  Downloading fastdtw-0.3.4.tar.gz (133 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/133.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fastdtw) (1.26.4)\n",
            "Building wheels for collected packages: fastdtw\n",
            "  Building wheel for fastdtw (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastdtw: filename=fastdtw-0.3.4-cp311-cp311-linux_x86_64.whl size=542097 sha256=1557271c63891b150f8594fc9b42139dd5b1fa30b6974f3a498385a410dbfb64\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/8a/f6/fd3df9a9714677410a5ccbf3ca519e66db4a54a1c46ea95332\n",
            "Successfully built fastdtw\n",
            "Installing collected packages: fastdtw\n",
            "Successfully installed fastdtw-0.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Lily: This is SNR with alignment preprocessing.\n",
        "\n",
        "import wave\n",
        "import numpy as np\n",
        "from scipy.signal import spectrogram\n",
        "import librosa\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import euclidean\n",
        "from fastdtw import fastdtw\n",
        "import soundfile as sf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Redefining file paths\n",
        "file1_path = 'F-F03-010.WAV'\n",
        "file2_path = 'E-F01-006.WAV'\n",
        "\n",
        "# Function to read WAV file and extract audio data\n",
        "def read_wav(file_path):\n",
        "    try:\n",
        "        with wave.open(file_path, 'r') as wav_file:\n",
        "            # Extract properties\n",
        "            n_channels = wav_file.getnchannels()\n",
        "            sample_width = wav_file.getsampwidth()\n",
        "            framerate = wav_file.getframerate()\n",
        "            n_frames = wav_file.getnframes()\n",
        "\n",
        "            # Read frames and convert to numpy array\n",
        "            audio_frames = wav_file.readframes(n_frames)\n",
        "            audio_data = np.frombuffer(audio_frames, dtype=np.int16)\n",
        "\n",
        "            # Handle stereo audio by taking only one channel if necessary\n",
        "            if n_channels > 1:\n",
        "                audio_data = audio_data[::n_channels]\n",
        "\n",
        "            return audio_data, framerate\n",
        "    except Exception as e:\n",
        "        return None, None\n",
        "\n",
        "# Read both audio files\n",
        "audio1, sr1 = read_wav(file1_path)\n",
        "audio2, sr2 = read_wav(file2_path)\n",
        "\n",
        "# Check the basic properties of the audio data\n",
        "audio1_properties = (len(audio1), sr1) if audio1 is not None else None\n",
        "audio2_properties = (len(audio2), sr2) if audio2 is not None else None\n",
        "\n",
        "print(audio1_properties, audio2_properties)\n",
        "\n",
        "# Function to calculate the spectrogram for alignment purposes\n",
        "def calculate_spectrogram(audio, sr, nperseg=512, noverlap=256):\n",
        "    f, t, Sxx = spectrogram(audio, fs=sr, nperseg=nperseg, noverlap=noverlap)\n",
        "    return f, t, Sxx\n",
        "\n",
        "# Calculate spectrograms for both audio files\n",
        "f1, t1, Sxx1 = calculate_spectrogram(audio1, sr1)\n",
        "f2, t2, Sxx2 = calculate_spectrogram(audio2, sr2)\n",
        "\n",
        "# Check the spectrogram dimensions for alignment feasibility\n",
        "Sxx1_shape = Sxx1.shape\n",
        "Sxx2_shape = Sxx2.shape\n",
        "\n",
        "print(Sxx1_shape, Sxx2_shape)\n",
        "\n",
        "# Function to load audio and compute MFCCs\n",
        "def extract_mfcc(file_path, n_mfcc=13):\n",
        "    y, sr = librosa.load(file_path, sr=None)\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
        "    return y, sr, mfcc\n",
        "\n",
        "# Load your audio files\n",
        "file1_path = \"F-F03-010.WAV\"\n",
        "file2_path = \"E-F01-006.WAV\"\n",
        "y1, sr1, mfcc1 = extract_mfcc(file1_path)\n",
        "y2, sr2, mfcc2 = extract_mfcc(file2_path)\n",
        "\n",
        "# Perform DTW on flattened MFCCs\n",
        "distance, path = fastdtw(mfcc1.T, mfcc2.T, dist=euclidean)\n",
        "\n",
        "print(f\"DTW Distance: {distance}\")\n",
        "print(f\"Path Length: {len(path)}\")\n",
        "\n",
        "def get_aligned_segments(path, frame_length, sr):\n",
        "    aligned_segments = []\n",
        "    current_segment = []\n",
        "    last_frame1, last_frame2 = -1, -1\n",
        "\n",
        "    for frame1, frame2 in path:\n",
        "        if last_frame1 + 1 == frame1 and last_frame2 + 1 == frame2:\n",
        "            # Continue current segment\n",
        "            current_segment.append((frame1, frame2))\n",
        "        else:\n",
        "            # Save completed segment\n",
        "            if current_segment:\n",
        "                aligned_segments.append(current_segment)\n",
        "            current_segment = [(frame1, frame2)]  # Start a new segment\n",
        "\n",
        "        last_frame1, last_frame2 = frame1, frame2\n",
        "\n",
        "    # Append the final segment\n",
        "    if current_segment:\n",
        "        aligned_segments.append(current_segment)\n",
        "\n",
        "    # Convert frame indices to time intervals\n",
        "    segments_in_time = [\n",
        "        ((seg[0][0] * frame_length) / sr, (seg[-1][0] * frame_length) / sr)\n",
        "        for seg in aligned_segments\n",
        "    ]\n",
        "    return segments_in_time\n",
        "\n",
        "frame_length = 512  # Window size used in the spectrogram\n",
        "aligned_time_segments = get_aligned_segments(path, frame_length, sr1)\n",
        "print(aligned_time_segments)\n",
        "\n",
        "def extract_segments(audio, sr, time_segments):\n",
        "    segments = []\n",
        "    for start_time, end_time in time_segments:\n",
        "        start_sample = int(start_time * sr)\n",
        "        end_sample = int(end_time * sr)\n",
        "        segments.append(audio[start_sample:end_sample])\n",
        "    return segments\n",
        "\n",
        "# Extract speech segments\n",
        "speech_segments = extract_segments(audio1, sr1, aligned_time_segments)\n",
        "\n",
        "def extract_noise_segments(audio, sr, time_segments):\n",
        "    noise_segments = []\n",
        "    last_end = 0\n",
        "    for start_time, end_time in time_segments:\n",
        "        start_sample = int(start_time * sr)\n",
        "        if start_sample > last_end:\n",
        "            noise_segments.append(audio[last_end:start_sample])\n",
        "        last_end = int(end_time * sr)\n",
        "    if last_end < len(audio):\n",
        "        noise_segments.append(audio[last_end:])\n",
        "    return noise_segments\n",
        "\n",
        "# Extract noise segments\n",
        "noise_segments = extract_noise_segments(audio1, sr1, aligned_time_segments)\n",
        "\n",
        "# Save a speech segment\n",
        "sf.write(\"speech_segment.wav\", speech_segments[0], sr1)\n",
        "\n",
        "# Save a noise segment\n",
        "sf.write(\"noise_segment.wav\", noise_segments[0], sr1)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(audio1, label=\"Original Audio\")\n",
        "for start_time, end_time in aligned_time_segments:\n",
        "    plt.axvspan(start_time * sr1, end_time * sr1, color=\"green\", alpha=0.3, label=\"Speech\")\n",
        "plt.legend()\n",
        "plt.title(\"Speech Segments\")\n",
        "plt.show()\n",
        "\n",
        "def calculate_snr(signal, noise):\n",
        "    signal_energy = np.sum(signal ** 2)\n",
        "    noise_energy = np.sum(noise ** 2)\n",
        "    snr = 10 * np.log10(signal_energy / noise_energy)\n",
        "    return snr\n",
        "\n",
        "# Example usage (replace with actual segmented signals and noise):\n",
        "speech_signal = y1[:10000]  # Example segment for speech\n",
        "background_noise = y1[10000:20000]  # Example segment for noise\n",
        "snr_value = calculate_snr(speech_signal, background_noise)\n",
        "print(f\"SNR: {snr_value:.2f} dB\")\n",
        "\n",
        "speech_segments = extract_segments(audio2, sr2, aligned_time_segments)\n",
        "noise_segments = extract_noise_segments(audio2, sr2, aligned_time_segments)\n",
        "sf.write(\"speech_segment.wav\", speech_segments[0], sr2)\n",
        "speech_signal = y2[:10000]  # Example speech segment from audio2\n",
        "background_noise = y2[10000:20000]  # Example noise segment from audio2\n",
        "snr_value = calculate_snr(speech_signal, background_noise)\n",
        "print(f\"SNR: {snr_value:.2f} dB\")"
      ],
      "metadata": {
        "id": "1NbW-iBf3see",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "c7d15661-6700-4997-bff4-2d2d9589bfe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None None\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'shape'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-fb880045d0ab>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# Calculate spectrograms for both audio files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSxx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_spectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSxx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_spectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-fb880045d0ab>\u001b[0m in \u001b[0;36mcalculate_spectrogram\u001b[0;34m(audio, sr, nperseg, noverlap)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# Function to calculate the spectrogram for alignment purposes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_spectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnperseg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoverlap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSxx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnperseg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnperseg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoverlap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoverlap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSxx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/signal/_spectral_py.py\u001b[0m in \u001b[0;36mspectrogram\u001b[0;34m(x, fs, window, nperseg, noverlap, nfft, detrend, return_onesided, scaling, axis, mode)\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[0;31m# need to set default for nperseg before setting default for noverlap below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m     window, nperseg = _triage_segments(window, nperseg,\n\u001b[0;32m--> 776\u001b[0;31m                                        input_length=x.shape[axis])\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0;31m# Less overlap than welch, so samples are more statisically independent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ]
    }
  ]
}