{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Benchmark Json\n"
      ],
      "metadata": {
        "id": "0IEneUE1f2XJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "EwA9SRlteIHY",
        "outputId": "dfbe541c-acdc-42a3-8162-fc5eeac98431"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './table.xlsx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-26f7cb63e0a6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0moutput_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"./{model_name}_benchmark_data.json\"\u001b[0m  \u001b[0;31m# Replace with your desired output file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0mspreadsheet_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./table.xlsx\"\u001b[0m  \u001b[0;31m# Replace with your spreadsheet path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m     \u001b[0mgenerate_json_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspreadsheet_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-26f7cb63e0a6>\u001b[0m in \u001b[0;36mgenerate_json_data\u001b[0;34m(folder_path, output_file, spreadsheet_path, model_name, runtime)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \"\"\"\n\u001b[1;32m    232\u001b[0m     \u001b[0maudio_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"*.wav\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m     \u001b[0mtag_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_tags_from_spreadsheet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspreadsheet_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0maudio_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-26f7cb63e0a6>\u001b[0m in \u001b[0;36mload_tags_from_spreadsheet\u001b[0;34m(spreadsheet_path)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_tags_from_spreadsheet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspreadsheet_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;34m\"\"\"Load tag information from a spreadsheet.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspreadsheet_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_default_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"N/A\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_tags_from_spreadsheet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         io = ExcelFile(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1551\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './table.xlsx'"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd # type: ignore\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import librosa\n",
        "import scipy.signal\n",
        "import scipy.io.wavfile as wav\n",
        "\n",
        "def total_harmonic_distortion(file_path): #ratio\n",
        "    # Load the audio signal\n",
        "    signal, sr = librosa.load(file_path, sr=None)\n",
        "\n",
        "    # Perform FFT on the signal\n",
        "    fft_spectrum = np.fft.fft(signal)\n",
        "    fft_magnitude = np.abs(fft_spectrum[:len(fft_spectrum) // 2])  # Only keep positive frequencies\n",
        "    freqs = np.fft.fftfreq(len(signal), d=1/sr)[:len(fft_spectrum) // 2]\n",
        "\n",
        "    # Find peaks in the FFT spectrum\n",
        "    peaks, properties = scipy.signal.find_peaks(fft_magnitude, height=np.max(fft_magnitude) * 0.1)  # Consider peaks above 10% max amplitude\n",
        "\n",
        "    if len(peaks) < 2:\n",
        "        raise ValueError(f\"Not enough peaks found to compute THD in file: {file_path}\")\n",
        "\n",
        "    # Sort peaks by amplitude (descending)\n",
        "    sorted_indices = np.argsort(properties[\"peak_heights\"])[::-1]\n",
        "    sorted_peaks = peaks[sorted_indices]\n",
        "\n",
        "    # Assume the highest peak is the fundamental frequency\n",
        "    fundamental_freq = freqs[sorted_peaks[0]]\n",
        "    fundamental_amp = fft_magnitude[sorted_peaks[0]]\n",
        "\n",
        "    # Compute THD by summing the power of the harmonics\n",
        "    harmonic_power = 0\n",
        "    for peak in sorted_peaks[1:]:  # Ignore fundamental, check harmonics\n",
        "        harmonic_freq = freqs[peak]\n",
        "        if np.isclose(harmonic_freq % fundamental_freq, 0, atol=1):  # Ensure it's a harmonic\n",
        "            harmonic_power += fft_magnitude[peak] ** 2\n",
        "\n",
        "    if harmonic_power == 0:\n",
        "        print(f\"No harmonics found for THD calculation in file: {file_path}\")\n",
        "\n",
        "    thd = (np.sqrt(harmonic_power) / fundamental_amp)\n",
        "    return thd\n",
        "\n",
        "def noise_floor(file_path, segment_duration=0.5): #decibels\n",
        "    # Load the audio signal\n",
        "    signal, sr = librosa.load(file_path, sr=None)\n",
        "\n",
        "    # Calculate segment length in samples\n",
        "    segment_length = int(segment_duration * sr)\n",
        "\n",
        "    # Split the signal into segments\n",
        "    segments = [signal[i:i + segment_length] for i in range(0, len(signal), segment_length)]\n",
        "\n",
        "    # Calculate RMS for each segment\n",
        "    rms_values = [np.sqrt(np.mean(segment**2)) for segment in segments]\n",
        "\n",
        "    # Average RMS value as the noise floor\n",
        "    noise_floor = np.mean(rms_values)\n",
        "\n",
        "    # Convert to decibels\n",
        "    noise_floor_db = 20 * np.log10(noise_floor)\n",
        "\n",
        "    return noise_floor_db\n",
        "\n",
        "\n",
        "def dynamic_range(file_path):  # Decibels\n",
        "    # Read the wav file\n",
        "    sample_rate, data = wav.read(file_path)\n",
        "\n",
        "    # Convert to float to avoid integer-related issues\n",
        "    data = data.astype(np.float32)\n",
        "\n",
        "    # Convert to mono if stereo\n",
        "    if len(data.shape) > 1:\n",
        "        data = np.mean(data, axis=1)  # Take mean of channels to make mono\n",
        "\n",
        "    # Remove NaN values properly\n",
        "    if np.isnan(data).any():\n",
        "        data = data[~np.isnan(data)]\n",
        "\n",
        "    # Ensure data isn't empty after filtering\n",
        "    if data.size == 0:\n",
        "        return float('-inf')  # Avoid errors in log calculation\n",
        "\n",
        "    # Compute peak amplitude\n",
        "    peak_amplitude = np.max(np.abs(data))\n",
        "\n",
        "    # Compute RMS amplitude safely to avoid log0\n",
        "    rms_amplitude = np.sqrt(np.mean(data**2) + 1e-10)\n",
        "\n",
        "    # Compute dynamic range in dB\n",
        "    dynamic_range = 20 * np.log10(peak_amplitude / rms_amplitude)\n",
        "\n",
        "    return dynamic_range\n",
        "\n",
        "\n",
        "def crest_factor(file_path, segment_duration=0.5):  # dB\n",
        "    # Load the audio signal\n",
        "    signal, sr = librosa.load(file_path, sr=None)\n",
        "\n",
        "    # Calculate segment length in samples\n",
        "    segment_length = int(segment_duration * sr)\n",
        "\n",
        "    # Split the signal into segments\n",
        "    segments = [signal[i:i + segment_length] for i in range(0, len(signal), segment_length)]\n",
        "\n",
        "    # Calculate peak and RMS for each segment\n",
        "    crest_factors = []\n",
        "    for segment in segments:\n",
        "        peak = np.max(np.abs(segment))\n",
        "        rms = np.sqrt(np.mean(segment**2))\n",
        "\n",
        "        # Compute crest factor in ratio and convert to dB\n",
        "        if rms > 0:\n",
        "            crest_factor_db = 20 * np.log10(peak / rms)\n",
        "            crest_factors.append(crest_factor_db)\n",
        "\n",
        "    # Average crest factor in dB across segments\n",
        "    average_crest_factor_db = np.mean(crest_factors) if crest_factors else float('-inf')\n",
        "\n",
        "    return average_crest_factor_db\n",
        "\n",
        "\n",
        "def signal_noise_ratio(file_path, noise_duration=0.5, signal_duration=2.0): #decibels\n",
        "    # Load the audio signal\n",
        "    signal, sr = librosa.load(file_path, sr=None)\n",
        "\n",
        "    # Calculate noise and signal lengths in samples\n",
        "    noise_length = int(noise_duration * sr)\n",
        "    signal_length = int(signal_duration * sr)\n",
        "\n",
        "    # Get noise and signal segments\n",
        "    noise_segment = signal[:noise_length]\n",
        "    signal_segment = signal[noise_length:noise_length + signal_length]\n",
        "\n",
        "    # Calculate RMS of noise and signal\n",
        "    noise_rms = np.sqrt(np.mean(noise_segment**2))\n",
        "    signal_rms = np.sqrt(np.mean(signal_segment**2))\n",
        "\n",
        "    # Calculate SNR in decibels\n",
        "    snr_db = 20 * np.log10(signal_rms / noise_rms) if noise_rms > 0 else float('inf')  # Avoid division by zero\n",
        "\n",
        "    return snr_db\n",
        "\n",
        "\n",
        "def waveform_complexity_index(file_path): #relative value\n",
        "    # Load audio file\n",
        "    signal, sr = librosa.load(file_path, sr=None, mono=True)\n",
        "\n",
        "    # Compute Zero-Crossing Rate (ZCR) - Measures frequency of sign changes\n",
        "    zcr = librosa.feature.zero_crossing_rate(y=signal)\n",
        "    avg_zcr = np.mean(zcr)\n",
        "\n",
        "    # Compute Spectral Entropy manually (Energy Distribution across Frequencies)\n",
        "    spectrum = np.abs(librosa.stft(signal))  # Compute magnitude spectrum\n",
        "    spectrum = spectrum / np.sum(spectrum, axis=0, keepdims=True)  # Normalize\n",
        "    spectral_entropy = scipy.stats.entropy(spectrum, axis=0)  # Compute entropy\n",
        "    avg_entropy = np.mean(spectral_entropy)\n",
        "\n",
        "    # Compute RMS Energy Variation - Measures fluctuations in loudness\n",
        "    rms_energy = librosa.feature.rms(y=signal)\n",
        "    rms_variation = np.std(rms_energy)  # Standard deviation to measure fluctuation\n",
        "\n",
        "    # Compute Waveform Complexity Index (WCI)\n",
        "    wci = (avg_zcr * avg_entropy) / (1 + rms_variation)  # Normalize by dynamic range\n",
        "    return wci\n",
        "\n",
        "# Load tags from a spreadsheet\n",
        "def load_tags_from_spreadsheet(spreadsheet_path):\n",
        "    \"\"\"Load tag information from a spreadsheet.\"\"\"\n",
        "    return pd.read_excel(spreadsheet_path, keep_default_na=True, na_values = [\"N/A\"])\n",
        "\n",
        "def get_tags_from_spreadsheet(file_name, tag_data):\n",
        "    \"\"\"\n",
        "    Extract tags for a specific file name from the spreadsheet data.\n",
        "\n",
        "    Args:\n",
        "        file_name (str): Name of the file to lookup (without extension).\n",
        "        tag_data (pd.DataFrame): DataFrame containing tag information.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary of tags for the file.\n",
        "    \"\"\"\n",
        "    file_name_no_ext = file_name.replace(\".wav\", \"\")  # Ensure extension is removed\n",
        "    row = tag_data[tag_data['ID'] == file_name_no_ext]\n",
        "    if not row.empty:\n",
        "        row = row.iloc[0]\n",
        "        print(\"Processed \" + file_name_no_ext)\n",
        "        return {\n",
        "            \"ID\": row.get(\"ID\", None),\n",
        "            \"Length\": int(row.get(\"Length (S)\", None)),\n",
        "            \"Location\": row.get(\"Location\", None),\n",
        "            \"Indoors\": row.get(\"Indoors\", None),\n",
        "            \"Crowded\": row.get(\"Crowded\", None),\n",
        "            \"Speaking\": row.get(\"Speaking\", None),\n",
        "            \"Walking\": row.get(\"Walking\", None),\n",
        "            \"Environment Type\": row.get(\"Environment Type\", None),\n",
        "            \"Voice Type\": str(row.get(\"Voice Type\", None)),\n",
        "            \"Voice ID\": str(row.get(\"Voice ID\", None))\n",
        "        }\n",
        "    return {}\n",
        "\n",
        "def process_audio(file_path):\n",
        "    \"\"\"\n",
        "    Process an audio file to calculate metrics.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the .wav file.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary of metrics with values.\n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"Total_Harmonic_Distortion\": float(total_harmonic_distortion(file_path)),\n",
        "        \"Signal_Noise_Ratio\": float(signal_noise_ratio(file_path)),\n",
        "        \"Noise_Floor\": float(noise_floor(file_path)),\n",
        "        \"Dynamic_Range\": float(dynamic_range(file_path)),\n",
        "        \"Crest_Factor\": float(crest_factor(file_path)),\n",
        "        \"Waveform_Complexity_Index\": float(waveform_complexity_index(file_path)),\n",
        "    }\n",
        "\n",
        "def generate_json_data(folder_path, output_file, spreadsheet_path, model_name, runtime):\n",
        "    \"\"\"\n",
        "    Generate JSON data for audio files in a folder.\n",
        "\n",
        "    Args:\n",
        "        folder_path (str): Path to the folder containing .wav files.\n",
        "        output_file (str): Path to the output JSON file.\n",
        "        spreadsheet_path (str): Path to the spreadsheet containing tag data.\n",
        "    \"\"\"\n",
        "    audio_files = list(Path(folder_path).rglob(\"*.wav\"))\n",
        "    tag_data = load_tags_from_spreadsheet(spreadsheet_path)\n",
        "\n",
        "    if not audio_files:\n",
        "        print(\"No .wav files found in the specified folder.\")\n",
        "        return\n",
        "\n",
        "    data_store = []\n",
        "\n",
        "    for file_path in audio_files:\n",
        "        file_name = file_path.stem\n",
        "        metrics = process_audio(file_path)\n",
        "        file_tags = get_tags_from_spreadsheet(file_name, tag_data)\n",
        "\n",
        "        entry = {\"ID\": file_name}\n",
        "        entry.update(file_tags)\n",
        "        entry.update(metrics)\n",
        "\n",
        "        data_store.append(entry)\n",
        "        print(f\"Successfully Added {file_path} to store\")\n",
        "\n",
        "    # Add top-level metrics\n",
        "    top_level_metrics = {\n",
        "        \"audio_model\": model_name,  # Replace with actual audio model name\n",
        "        \"runtime\": runtime # runtime in seconds\n",
        "    }\n",
        "\n",
        "    # Combine top-level metrics with data_store\n",
        "    output_data = {\n",
        "        \"top_level_metrics\": top_level_metrics,\n",
        "        \"files\": data_store\n",
        "    }\n",
        "\n",
        "    # Save the data to a JSON file\n",
        "    with open(output_file, \"w\") as json_file:\n",
        "        json.dump(output_data, json_file, indent=4)\n",
        "\n",
        "    print(f\"JSON data saved to {output_file}\")\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    folder_path = \"./Spectral_Subtraction\"  # Replace with your folder path\n",
        "    model_name = \"spectral_subtraction\" # Replace with model title\n",
        "    output_file = f\"./{model_name}_benchmark_data.json\"  # Replace with your desired output file\n",
        "    spreadsheet_path = \"./table.xlsx\"  # Replace with your spreadsheet path\n",
        "    generate_json_data(folder_path, output_file, spreadsheet_path, model_name, 0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Compare Benchmark Jsons"
      ],
      "metadata": {
        "id": "JL1LuncvfxDL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ALL MODELS**"
      ],
      "metadata": {
        "id": "XKvYZfdi15G-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd # type: ignore\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import librosa\n",
        "import scipy.signal\n",
        "import scipy.io.wavfile as wav\n",
        "def total_harmonic_distortion(file_path): #ratio\n",
        "    # Load the audio signal\n",
        "    signal, sr = librosa.load(file_path, sr=None)\n",
        "\n",
        "    # Perform FFT on the signal\n",
        "    fft_spectrum = np.fft.fft(signal)\n",
        "    fft_magnitude = np.abs(fft_spectrum[:len(fft_spectrum) // 2])  # Only keep positive frequencies\n",
        "    freqs = np.fft.fftfreq(len(signal), d=1/sr)[:len(fft_spectrum) // 2]\n",
        "\n",
        "    # Find peaks in the FFT spectrum\n",
        "    peaks, properties = scipy.signal.find_peaks(fft_magnitude, height=np.max(fft_magnitude) * 0.1)  # Consider peaks above 10% max amplitude\n",
        "\n",
        "    if len(peaks) < 2:\n",
        "        raise ValueError(f\"Not enough peaks found to compute THD in file: {file_path}\")\n",
        "\n",
        "    # Sort peaks by amplitude (descending)\n",
        "    sorted_indices = np.argsort(properties[\"peak_heights\"])[::-1]\n",
        "    sorted_peaks = peaks[sorted_indices]\n",
        "\n",
        "    # Assume the highest peak is the fundamental frequency\n",
        "    fundamental_freq = freqs[sorted_peaks[0]]\n",
        "    fundamental_amp = fft_magnitude[sorted_peaks[0]]\n",
        "\n",
        "    # Compute THD by summing the power of the harmonics\n",
        "    harmonic_power = 0\n",
        "    for peak in sorted_peaks[1:]:  # Ignore fundamental, check harmonics\n",
        "        harmonic_freq = freqs[peak]\n",
        "        if np.isclose(harmonic_freq % fundamental_freq, 0, atol=1):  # Ensure it's a harmonic\n",
        "            harmonic_power += fft_magnitude[peak] ** 2\n",
        "\n",
        "    if harmonic_power == 0:\n",
        "        print(f\"No harmonics found for THD calculation in file: {file_path}\")\n",
        "\n",
        "    thd = (np.sqrt(harmonic_power) / fundamental_amp)\n",
        "    return thd\n",
        "\n",
        "def noise_floor(file_path, segment_duration=0.5): #decibels\n",
        "    # Load the audio signal\n",
        "    signal, sr = librosa.load(file_path, sr=None)\n",
        "\n",
        "    # Calculate segment length in samples\n",
        "    segment_length = int(segment_duration * sr)\n",
        "\n",
        "    # Split the signal into segments\n",
        "    segments = [signal[i:i + segment_length] for i in range(0, len(signal), segment_length)]\n",
        "\n",
        "    # Calculate RMS for each segment\n",
        "    rms_values = [np.sqrt(np.mean(segment**2)) for segment in segments]\n",
        "\n",
        "    # Average RMS value as the noise floor\n",
        "    noise_floor = np.mean(rms_values)\n",
        "\n",
        "    # Convert to decibels\n",
        "    noise_floor_db = 20 * np.log10(noise_floor)\n",
        "\n",
        "    return noise_floor_db\n",
        "\n",
        "\n",
        "def dynamic_range(file_path):  # Decibels\n",
        "    # Read the wav file\n",
        "    sample_rate, data = wav.read(file_path)\n",
        "\n",
        "    # Convert to float to avoid integer-related issues\n",
        "    data = data.astype(np.float32)\n",
        "\n",
        "    # Convert to mono if stereo\n",
        "    if len(data.shape) > 1:\n",
        "        data = np.mean(data, axis=1)  # Take mean of channels to make mono\n",
        "\n",
        "    # Remove NaN values properly\n",
        "    if np.isnan(data).any():\n",
        "        data = data[~np.isnan(data)]\n",
        "\n",
        "    # Ensure data isn't empty after filtering\n",
        "    if data.size == 0:\n",
        "        return float('-inf')  # Avoid errors in log calculation\n",
        "\n",
        "    # Compute peak amplitude\n",
        "    peak_amplitude = np.max(np.abs(data))\n",
        "\n",
        "    # Compute RMS amplitude safely avoiding log(0)\n",
        "    rms_amplitude = np.sqrt(np.mean(data**2) + 1e-10)\n",
        "\n",
        "    # Compute dynamic range in dB\n",
        "    dynamic_range = 20 * np.log10(peak_amplitude / rms_amplitude)\n",
        "\n",
        "    return dynamic_range\n",
        "\n",
        "\n",
        "def crest_factor(file_path, segment_duration=0.5):  # dB\n",
        "    # Load the audio signal\n",
        "    signal, sr = librosa.load(file_path, sr=None)\n",
        "\n",
        "    # Calculate segment length in samples\n",
        "    segment_length = int(segment_duration * sr)\n",
        "\n",
        "    # Split the signal into segments\n",
        "    segments = [signal[i:i + segment_length] for i in range(0, len(signal), segment_length)]\n",
        "\n",
        "    # Calculate peak and RMS for each segment\n",
        "    crest_factors = []\n",
        "    for segment in segments:\n",
        "        peak = np.max(np.abs(segment))\n",
        "        rms = np.sqrt(np.mean(segment**2))\n",
        "\n",
        "        # Compute crest factor in ratio and convert to dB\n",
        "        if rms > 0:\n",
        "            crest_factor_db = 20 * np.log10(peak / rms)\n",
        "            crest_factors.append(crest_factor_db)\n",
        "\n",
        "    # Average crest factor in dB across segments\n",
        "    average_crest_factor_db = np.mean(crest_factors) if crest_factors else float('-inf')\n",
        "\n",
        "    return average_crest_factor_db\n",
        "\n",
        "\n",
        "def signal_noise_ratio(file_path, noise_duration=0.5, signal_duration=2.0): #decibels\n",
        "    # Load the audio signal\n",
        "    signal, sr = librosa.load(file_path, sr=None)\n",
        "\n",
        "    # Calculate noise and signal lengths in samples\n",
        "    noise_length = int(noise_duration * sr)\n",
        "    signal_length = int(signal_duration * sr)\n",
        "\n",
        "    # Get noise and signal segments\n",
        "    noise_segment = signal[:noise_length]\n",
        "    signal_segment = signal[noise_length:noise_length + signal_length]\n",
        "\n",
        "    # Calculate RMS of noise and signal\n",
        "    noise_rms = np.sqrt(np.mean(noise_segment**2))\n",
        "    signal_rms = np.sqrt(np.mean(signal_segment**2))\n",
        "\n",
        "    # Calculate SNR in decibels\n",
        "    snr_db = 20 * np.log10(signal_rms / noise_rms) if noise_rms > 0 else float('inf')  # Avoid division by zero\n",
        "\n",
        "    return snr_db\n",
        "\n",
        "\n",
        "def waveform_complexity_index(file_path): #relative value\n",
        "    # Load audio file\n",
        "    signal, sr = librosa.load(file_path, sr=None, mono=True)\n",
        "\n",
        "    # Compute Zero-Crossing Rate (ZCR) - Measures frequency of sign changes\n",
        "    zcr = librosa.feature.zero_crossing_rate(y=signal)\n",
        "    avg_zcr = np.mean(zcr)\n",
        "\n",
        "    # Compute Spectral Entropy manually (Energy Distribution across Frequencies)\n",
        "    spectrum = np.abs(librosa.stft(signal))  # Compute magnitude spectrum\n",
        "    spectrum = spectrum / np.sum(spectrum, axis=0, keepdims=True)  # Normalize\n",
        "    spectral_entropy = scipy.stats.entropy(spectrum, axis=0)  # Compute entropy\n",
        "    avg_entropy = np.mean(spectral_entropy)\n",
        "\n",
        "    # Compute RMS Energy Variation - Measures fluctuations in loudness\n",
        "    rms_energy = librosa.feature.rms(y=signal)\n",
        "    rms_variation = np.std(rms_energy)  # Standard deviation to measure fluctuation\n",
        "\n",
        "    # Compute Waveform Complexity Index (WCI)\n",
        "    wci = (avg_zcr * avg_entropy) / (1 + rms_variation)  # Normalize by dynamic range\n",
        "    return wci\n"
      ],
      "metadata": {
        "id": "LHNruVeJ1zOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xujYPYfc2FHH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}